{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install and Run the CD-HIT"
      ],
      "metadata": {
        "id": "zPtyuyTyh7Cl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKHNc_5oZCsl",
        "outputId": "ee7ab1a2-d23c-4280-91a2-c3f61e5b8940"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [Waiting for headers] [1\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [Waiting for headers] [C\r                                                                               \rGet:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,188 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,527 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,224 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,626 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,454 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,513 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,738 kB]\n",
            "Fetched 20.7 MB in 7s (2,938 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "wget is already the newest version (1.21.2-2ubuntu1.1).\n",
            "zlib1g-dev is already the newest version (1:1.2.11.dfsg-2ubuntu9.2).\n",
            "zlib1g-dev set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 51 not upgraded.\n",
            "--2024-12-04 00:49:56--  https://github.com/weizhongli/cdhit/archive/refs/tags/V4.8.1.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.116.4\n",
            "Connecting to github.com (github.com)|140.82.116.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/weizhongli/cdhit/tar.gz/refs/tags/V4.8.1 [following]\n",
            "--2024-12-04 00:49:56--  https://codeload.github.com/weizhongli/cdhit/tar.gz/refs/tags/V4.8.1\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.112.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.112.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: ‘cdhit.tar.gz’\n",
            "\n",
            "cdhit.tar.gz            [  <=>               ] 923.48K  2.32MB/s    in 0.4s    \n",
            "\n",
            "2024-12-04 00:49:57 (2.32 MB/s) - ‘cdhit.tar.gz’ saved [945639]\n",
            "\n",
            "cdhit-4.8.1/\n",
            "cdhit-4.8.1/ChangeLog\n",
            "cdhit-4.8.1/FET.pl\n",
            "cdhit-4.8.1/Makefile\n",
            "cdhit-4.8.1/README\n",
            "cdhit-4.8.1/cd-hit-2d-para.pl\n",
            "cdhit-4.8.1/cd-hit-auxtools/\n",
            "cdhit-4.8.1/cd-hit-auxtools/Makefile\n",
            "cdhit-4.8.1/cd-hit-auxtools/bioSequence.cxx\n",
            "cdhit-4.8.1/cd-hit-auxtools/bioSequence.hxx\n",
            "cdhit-4.8.1/cd-hit-auxtools/cd-hit-dup-PE-out.pl\n",
            "cdhit-4.8.1/cd-hit-auxtools/cdhit-dup.cxx\n",
            "cdhit-4.8.1/cd-hit-auxtools/cdhit-lap.cxx\n",
            "cdhit-4.8.1/cd-hit-auxtools/mintlib/\n",
            "cdhit-4.8.1/cd-hit-auxtools/mintlib/minArray.hxx\n",
            "cdhit-4.8.1/cd-hit-auxtools/mintlib/minBase.hxx\n",
            "cdhit-4.8.1/cd-hit-auxtools/mintlib/minMap.cxx\n",
            "cdhit-4.8.1/cd-hit-auxtools/mintlib/minMap.hxx\n",
            "cdhit-4.8.1/cd-hit-auxtools/mintlib/minString.cxx\n",
            "cdhit-4.8.1/cd-hit-auxtools/mintlib/minString.hxx\n",
            "cdhit-4.8.1/cd-hit-auxtools/mintlib/minUtility.hxx\n",
            "cdhit-4.8.1/cd-hit-auxtools/read-linker.cxx\n",
            "cdhit-4.8.1/cd-hit-clstr_2_blm8.pl\n",
            "cdhit-4.8.1/cd-hit-div.pl\n",
            "cdhit-4.8.1/cd-hit-para.pl\n",
            "cdhit-4.8.1/cdhit-2d.c++\n",
            "cdhit-4.8.1/cdhit-454.c++\n",
            "cdhit-4.8.1/cdhit-common.c++\n",
            "cdhit-4.8.1/cdhit-common.h\n",
            "cdhit-4.8.1/cdhit-div.c++\n",
            "cdhit-4.8.1/cdhit-est-2d.c++\n",
            "cdhit-4.8.1/cdhit-est.c++\n",
            "cdhit-4.8.1/cdhit-utility.c++\n",
            "cdhit-4.8.1/cdhit-utility.h\n",
            "cdhit-4.8.1/cdhit.c++\n",
            "cdhit-4.8.1/clstr2tree.pl\n",
            "cdhit-4.8.1/clstr2txt.pl\n",
            "cdhit-4.8.1/clstr2xml.pl\n",
            "cdhit-4.8.1/clstr_cut.pl\n",
            "cdhit-4.8.1/clstr_list.pl\n",
            "cdhit-4.8.1/clstr_list_sort.pl\n",
            "cdhit-4.8.1/clstr_merge.pl\n",
            "cdhit-4.8.1/clstr_merge_noorder.pl\n",
            "cdhit-4.8.1/clstr_quality_eval.pl\n",
            "cdhit-4.8.1/clstr_quality_eval_by_link.pl\n",
            "cdhit-4.8.1/clstr_reduce.pl\n",
            "cdhit-4.8.1/clstr_renumber.pl\n",
            "cdhit-4.8.1/clstr_rep.pl\n",
            "cdhit-4.8.1/clstr_reps_faa_rev.pl\n",
            "cdhit-4.8.1/clstr_rev.pl\n",
            "cdhit-4.8.1/clstr_select.pl\n",
            "cdhit-4.8.1/clstr_select_rep.pl\n",
            "cdhit-4.8.1/clstr_size_histogram.pl\n",
            "cdhit-4.8.1/clstr_size_stat.pl\n",
            "cdhit-4.8.1/clstr_sort_by.pl\n",
            "cdhit-4.8.1/clstr_sort_prot_by.pl\n",
            "cdhit-4.8.1/clstr_sql_tbl.pl\n",
            "cdhit-4.8.1/clstr_sql_tbl_sort.pl\n",
            "cdhit-4.8.1/doc/\n",
            "cdhit-4.8.1/doc/Figure1.png\n",
            "cdhit-4.8.1/doc/Figure2.png\n",
            "cdhit-4.8.1/doc/Figure3.png\n",
            "cdhit-4.8.1/doc/Figure4.png\n",
            "cdhit-4.8.1/doc/cd-hit-otu-miseq-Figure-1.png\n",
            "cdhit-4.8.1/doc/cdhit-user-guide.pdf\n",
            "cdhit-4.8.1/doc/cdhit-user-guide.tex\n",
            "cdhit-4.8.1/doc/cdhit-user-guide.wiki\n",
            "cdhit-4.8.1/doc/dokuwiki2latex.dao\n",
            "cdhit-4.8.1/license.txt\n",
            "cdhit-4.8.1/make_multi_seq.pl\n",
            "cdhit-4.8.1/plot_2d.pl\n",
            "cdhit-4.8.1/plot_len1.pl\n",
            "cdhit-4.8.1/psi-cd-hit/\n",
            "cdhit-4.8.1/psi-cd-hit/README.psi-cd-hit\n",
            "cdhit-4.8.1/psi-cd-hit/cd-hit-div.pl\n",
            "cdhit-4.8.1/psi-cd-hit/clstr_select_rep.pl\n",
            "cdhit-4.8.1/psi-cd-hit/clstr_select_seq.pl\n",
            "cdhit-4.8.1/psi-cd-hit/fetch_fasta_by_ids.pl\n",
            "cdhit-4.8.1/psi-cd-hit/fetch_fasta_exclude_ids.pl\n",
            "cdhit-4.8.1/psi-cd-hit/psi-2d.pl\n",
            "cdhit-4.8.1/psi-cd-hit/psi-cd-hit-local-old.pl\n",
            "cdhit-4.8.1/psi-cd-hit/psi-cd-hit-local.pl\n",
            "cdhit-4.8.1/psi-cd-hit/psi-cd-hit-old.pl\n",
            "cdhit-4.8.1/psi-cd-hit/psi-cd-hit.pl\n",
            "cdhit-4.8.1/psi-cd-hit/qsub-template\n",
            "cdhit-4.8.1/usecases/\n",
            "cdhit-4.8.1/usecases/Miseq-16S/\n",
            "cdhit-4.8.1/usecases/Miseq-16S/16S-ref-db-PE-splice.pl\n",
            "cdhit-4.8.1/usecases/Miseq-16S/NG-Omics-Miseq-16S.pl\n",
            "cdhit-4.8.1/usecases/Miseq-16S/NG-Omics-Miseq-16S.py\n",
            "cdhit-4.8.1/usecases/Miseq-16S/NG-Omics-WF.pl\n",
            "cdhit-4.8.1/usecases/Miseq-16S/NG-Omics-WF.py\n",
            "cdhit-4.8.1/usecases/Miseq-16S/README\n",
            "cdhit-4.8.1/usecases/Miseq-16S/cd-hit-otu-miseq-PE.pl\n",
            "cdhit-4.8.1/usecases/Miseq-16S/clstr_2_OTU_table.pl\n",
            "cdhit-4.8.1/usecases/Miseq-16S/filter-chimeric-and-small.pl\n",
            "cdhit-4.8.1/usecases/Miseq-16S/filter-chimeric-by-ref.pl\n",
            "cdhit-4.8.1/usecases/Miseq-16S/filter-nontop-ref.pl\n",
            "cdhit-4.8.1/usecases/Miseq-16S/filter-refonly-cluster.pl\n",
            "cdhit-4.8.1/usecases/Miseq-16S/greengene-ann1.pl\n",
            "cdhit-4.8.1/usecases/Miseq-16S/pool_samples.pl\n",
            "cdhit-4.8.1/usecases/Miseq-16S/silva-ana1.pl\n",
            "cdhit-4.8.1/usecases/miRNA-seq/\n",
            "cdhit-4.8.1/usecases/miRNA-seq/NG-Omics-miRNA-seq.pl\n",
            "cdhit-4.8.1/usecases/miRNA-seq/clstr_2_miRNA-table.pl\n",
            "cdhit-4.8.1/usecases/miRNA-seq/filter-small-cluster.pl\n",
            "g++  -fopenmp -DWITH_ZLIB -O2  cdhit-common.c++ -c\n",
            "In file included from \u001b[01m\u001b[Kcdhit-common.c++:28\u001b[m\u001b[K:\n",
            "In member function ‘\u001b[01m\u001b[Kvoid NVector<TYPE>::Resize(int, const TYPE&) [with TYPE = long int]\u001b[m\u001b[K’,\n",
            "    inlined from ‘\u001b[01m\u001b[KNVector<TYPE>::NVector(int, const TYPE&) [with TYPE = long int]\u001b[m\u001b[K’ at \u001b[01m\u001b[Kcdhit-common.h:119:10\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[Kint local_band_align(char*, char*, int, int, ScoreMatrix&, int&, int&, int&, float&, int*, int, int, int, WorkingBuffer&)\u001b[m\u001b[K’ at \u001b[01m\u001b[Kcdhit-common.c++:815:36\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kcdhit-common.h:144:55:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kargument 1 range [18446744056529682448, 18446744073709551608] exceeds maximum object size 9223372036854775807 [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Walloc-size-larger-than=\u0007-Walloc-size-larger-than=\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  144 |                                 items = (TYPE*)\u001b[01;35m\u001b[Krealloc( items, capacity*sizeof(TYPE) )\u001b[m\u001b[K;\n",
            "      |                                                \u001b[01;35m\u001b[K~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcdhit-common.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint local_band_align(char*, char*, int, int, ScoreMatrix&, int&, int&, int&, float&, int*, int, int, int, WorkingBuffer&)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kcdhit-common.h:144:55:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin a call to built-in allocation function ‘\u001b[01m\u001b[Kvoid* __builtin_malloc(long unsigned int)\u001b[m\u001b[K’\n",
            "g++  -fopenmp -DWITH_ZLIB -O2  cdhit-utility.c++ -c\n",
            "g++  -fopenmp -DWITH_ZLIB -O2  cdhit.c++ -c\n",
            "g++  -fopenmp -DWITH_ZLIB -O2  cdhit.o cdhit-common.o cdhit-utility.o -lz -o cd-hit\n",
            "g++  -fopenmp -DWITH_ZLIB -O2  cdhit-est.c++ -c\n",
            "g++  -fopenmp -DWITH_ZLIB -O2  cdhit-est.o cdhit-common.o cdhit-utility.o -lz -o cd-hit-est\n",
            "g++  -fopenmp -DWITH_ZLIB -O2  cdhit-2d.c++ -c\n",
            "g++  -fopenmp -DWITH_ZLIB -O2  cdhit-2d.o cdhit-common.o cdhit-utility.o -lz -o cd-hit-2d\n",
            "g++  -fopenmp -DWITH_ZLIB -O2  cdhit-est-2d.c++ -c\n",
            "g++  -fopenmp -DWITH_ZLIB -O2  cdhit-est-2d.o cdhit-common.o cdhit-utility.o -lz -o cd-hit-est-2d\n",
            "g++  -fopenmp -DWITH_ZLIB -O2  cdhit-div.c++ -c\n",
            "g++  -fopenmp -DWITH_ZLIB -O2  cdhit-div.o cdhit-common.o cdhit-utility.o -lz -o cd-hit-div\n",
            "g++  -fopenmp -DWITH_ZLIB -O2  cdhit-454.c++ -c\n",
            "g++  -fopenmp -DWITH_ZLIB -O2  cdhit-454.o cdhit-common.o cdhit-utility.o -lz -o cd-hit-454\n",
            "cp: -r not specified; omitting directory 'cdhit-4.8.1/cd-hit-auxtools'\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install build-essential wget zlib1g-dev\n",
        "!wget https://github.com/weizhongli/cdhit/archive/refs/tags/V4.8.1.tar.gz -O cdhit.tar.gz\n",
        "!tar -xvf cdhit.tar.gz\n",
        "!cd cdhit-4.8.1 && make\n",
        "!mkdir -p /content/cdhit_bin\n",
        "!cp cdhit-4.8.1/cd-hit* /content/cdhit_bin/\n",
        "!cp -r cdhit-4.8.1/cd-hit-auxtools /content/cdhit_bin/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install biopython"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIG9x46ZfMPq",
        "outputId": "31d770cd-a013-4507-81bf-2106b8a6ab96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biopython\n",
            "  Downloading biopython-1.84-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.26.4)\n",
            "Downloading biopython-1.84-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/3.2 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: biopython\n",
            "Successfully installed biopython-1.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/cdhit_bin/cd-hit -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRAh_9ktZWXC",
        "outputId": "2c5f2cc8-0e25-4594-a8ca-4bf2f0e8e6e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\t====== CD-HIT version 4.8.1 (built on Dec  4 2024) ======\n",
            "\n",
            "Usage: /content/cdhit_bin/cd-hit [Options] \n",
            "\n",
            "Options\n",
            "\n",
            "   -i\tinput filename in fasta format, required, can be in .gz format\n",
            "   -o\toutput filename, required\n",
            "   -c\tsequence identity threshold, default 0.9\n",
            " \tthis is the default cd-hit's \"global sequence identity\" calculated as:\n",
            " \tnumber of identical amino acids or bases in alignment\n",
            " \tdivided by the full length of the shorter sequence\n",
            "   -G\tuse global sequence identity, default 1\n",
            " \tif set to 0, then use local sequence identity, calculated as :\n",
            " \tnumber of identical amino acids or bases in alignment\n",
            " \tdivided by the length of the alignment\n",
            " \tNOTE!!! don't use -G 0 unless you use alignment coverage controls\n",
            " \tsee options -aL, -AL, -aS, -AS\n",
            "   -b\tband_width of alignment, default 20\n",
            "   -M\tmemory limit (in MB) for the program, default 800; 0 for unlimitted;\n",
            "   -T\tnumber of threads, default 1; with 0, all CPUs will be used\n",
            "   -n\tword_length, default 5, see user's guide for choosing it\n",
            "   -l\tlength of throw_away_sequences, default 10\n",
            "   -t\ttolerance for redundance, default 2\n",
            "   -d\tlength of description in .clstr file, default 20\n",
            " \tif set to 0, it takes the fasta defline and stops at first space\n",
            "   -s\tlength difference cutoff, default 0.0\n",
            " \tif set to 0.9, the shorter sequences need to be\n",
            " \tat least 90% length of the representative of the cluster\n",
            "   -S\tlength difference cutoff in amino acid, default 999999\n",
            " \tif set to 60, the length difference between the shorter sequences\n",
            " \tand the representative of the cluster can not be bigger than 60\n",
            "   -aL\talignment coverage for the longer sequence, default 0.0\n",
            " \tif set to 0.9, the alignment must covers 90% of the sequence\n",
            "   -AL\talignment coverage control for the longer sequence, default 99999999\n",
            " \tif set to 60, and the length of the sequence is 400,\n",
            " \tthen the alignment must be >= 340 (400-60) residues\n",
            "   -aS\talignment coverage for the shorter sequence, default 0.0\n",
            " \tif set to 0.9, the alignment must covers 90% of the sequence\n",
            "   -AS\talignment coverage control for the shorter sequence, default 99999999\n",
            " \tif set to 60, and the length of the sequence is 400,\n",
            " \tthen the alignment must be >= 340 (400-60) residues\n",
            "   -A\tminimal alignment coverage control for the both sequences, default 0\n",
            " \talignment must cover >= this value for both sequences \n",
            "   -uL\tmaximum unmatched percentage for the longer sequence, default 1.0\n",
            " \tif set to 0.1, the unmatched region (excluding leading and tailing gaps)\n",
            " \tmust not be more than 10% of the sequence\n",
            "   -uS\tmaximum unmatched percentage for the shorter sequence, default 1.0\n",
            " \tif set to 0.1, the unmatched region (excluding leading and tailing gaps)\n",
            " \tmust not be more than 10% of the sequence\n",
            "   -U\tmaximum unmatched length, default 99999999\n",
            " \tif set to 10, the unmatched region (excluding leading and tailing gaps)\n",
            " \tmust not be more than 10 bases\n",
            "   -B\t1 or 0, default 0, by default, sequences are stored in RAM\n",
            " \tif set to 1, sequence are stored on hard drive\n",
            " \t!! No longer supported !!\n",
            "   -p\t1 or 0, default 0\n",
            " \tif set to 1, print alignment overlap in .clstr file\n",
            "   -g\t1 or 0, default 0\n",
            " \tby cd-hit's default algorithm, a sequence is clustered to the first \n",
            " \tcluster that meet the threshold (fast cluster). If set to 1, the program\n",
            " \twill cluster it into the most similar cluster that meet the threshold\n",
            " \t(accurate but slow mode)\n",
            " \tbut either 1 or 0 won't change the representatives of final clusters\n",
            "   -sc\tsort clusters by size (number of sequences), default 0, output clusters by decreasing length\n",
            " \tif set to 1, output clusters by decreasing size\n",
            "   -sf\tsort fasta/fastq by cluster size (number of sequences), default 0, no sorting\n",
            " \tif set to 1, output sequences by decreasing cluster size\n",
            " \tthis can be very slow if the input is in .gz format\n",
            "   -bak\twrite backup cluster file (1 or 0, default 0)\n",
            "   -h\tprint this help\n",
            "\n",
            "   Questions, bugs, contact Weizhong Li at liwz@sdsc.edu\n",
            "   For updated versions and information, please visit: http://cd-hit.org\n",
            "                                                    or https://github.com/weizhongli/cdhit\n",
            "\n",
            "   cd-hit web server is also available from http://cd-hit.org\n",
            "\n",
            "   If you find cd-hit useful, please kindly cite:\n",
            "\n",
            "   \"CD-HIT: a fast program for clustering and comparing large sets of protein or nucleotide sequences\", Weizhong Li & Adam Godzik. Bioinformatics, (2006) 22:1658-1659\n",
            "   \"CD-HIT: accelerated for clustering the next generation sequencing data\", Limin Fu, Beifang Niu, Zhengwei Zhu, Sitao Wu & Weizhong Li. Bioinformatics, (2012) 28:3150-3152\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/cdhit_bin/cd-hit -i ZN_samples.fasta -o clustered_ZN.fasta -c 0.4 -n 2 # the input file name should be changed based on Pre_processing_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pswQ2zvhLS9J",
        "outputId": "f8a95b5f-e341-4dc4-a4b2-8b6218fc4c6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================\n",
            "Program: CD-HIT, V4.8.1 (+OpenMP), Dec 04 2024, 00:49:58\n",
            "Command: /content/cdhit_bin/cd-hit -i ZN_samples.fasta -o\n",
            "         clustered_ZN.fasta -c 0.4 -n 2\n",
            "\n",
            "Started: Wed Dec  4 00:50:42 2024\n",
            "================================================================\n",
            "                            Output                              \n",
            "----------------------------------------------------------------\n",
            "total seq: 481\n",
            "longest and shortest : 667 and 55\n",
            "Total letters: 130070\n",
            "Sequences have been sorted\n",
            "\n",
            "Approximated minimal memory consumption:\n",
            "Sequence        : 0M\n",
            "Buffer          : 1 X 10M = 10M\n",
            "Table           : 1 X 0M = 0M\n",
            "Miscellaneous   : 0M\n",
            "Total           : 10M\n",
            "\n",
            "Table limit with the given memory limit:\n",
            "Max number of representatives: 1743342\n",
            "Max number of word counting entries: 98644199\n",
            "\n",
            "\rcomparing sequences from          0  to        481\n",
            "\n",
            "      481  finished        118  clusters\n",
            "\n",
            "Approximated maximum memory consumption: 10M\n",
            "writing new database\n",
            "writing clustering information\n",
            "program completed !\n",
            "\n",
            "Total CPU time 0.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting the data into training and testing sets"
      ],
      "metadata": {
        "id": "WpsJ51X0hzz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from Bio import SeqIO\n",
        "\n",
        "# Read cluster file and create a dictionary mapping sequences to clusters\n",
        "def parse_cluster_file(cluster_file):\n",
        "    clusters = {}\n",
        "    current_cluster = None\n",
        "    with open(cluster_file, 'r') as f:\n",
        "        for line in f:\n",
        "            if line.startswith('>Cluster'):\n",
        "                current_cluster = line.strip()\n",
        "                clusters[current_cluster] = []\n",
        "            else:\n",
        "                sequence_id = line.strip().split(\">\")[1].split(\"...\")[0]\n",
        "                clusters[current_cluster].append(sequence_id)\n",
        "    return clusters\n",
        "\n",
        "# Split clusters into training and testing sets\n",
        "def split_clusters(clusters, train_ratio=0.8):\n",
        "    cluster_keys = list(clusters.keys())\n",
        "    random.shuffle(cluster_keys)\n",
        "    split_point = int(train_ratio * len(cluster_keys))\n",
        "    train_clusters = {key: clusters[key] for key in cluster_keys[:split_point]}\n",
        "    test_clusters = {key: clusters[key] for key in cluster_keys[split_point:]}\n",
        "    return train_clusters, test_clusters\n",
        "\n",
        "# Write sequences to fasta file based on clusters\n",
        "def write_fasta_file(original_fasta_file, clusters, output_file):\n",
        "    sequences = SeqIO.to_dict(SeqIO.parse(original_fasta_file, \"fasta\"))\n",
        "    selected_sequences = []\n",
        "\n",
        "    for cluster in clusters.values():\n",
        "        for seq_id in cluster:\n",
        "            if seq_id in sequences:\n",
        "                selected_sequences.append(sequences[seq_id])\n",
        "\n",
        "    SeqIO.write(selected_sequences, output_file, \"fasta\")\n",
        "\n",
        "# Main script\n",
        "cluster_file = 'clustered_ZN.fasta.clstr'  # should be changed based on the above\n",
        "original_fasta_file = 'clustered_ZN.fasta' # should be changed based on the above\n",
        "all_sequences_file = 'ZN_samples.fasta'  # the input file name should be changed based on Pre_processing_1 (all original sequences file without hashes)\n",
        "train_output_file = 'train_set.fasta'\n",
        "test_output_file = 'test_set.fasta'\n",
        "\n",
        "# Parse the cluster file\n",
        "clusters = parse_cluster_file(cluster_file)\n",
        "\n",
        "# Split clusters into training and testing sets\n",
        "train_clusters, test_clusters = split_clusters(clusters)\n",
        "\n",
        "# Write training and testing fasta files\n",
        "write_fasta_file(all_sequences_file, train_clusters, train_output_file)\n",
        "write_fasta_file(all_sequences_file, test_clusters, test_output_file)\n",
        "\n",
        "print(f'Training set saved to {train_output_file}')\n",
        "print(f'Testing set saved to {test_output_file}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrXCt-5EmUgU",
        "outputId": "5dd41831-416c-4011-8e97-d33d19a4a84d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set saved to train_set.fasta\n",
            "Testing set saved to test_set.fasta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Splitting the data into training, evaluating, and testing"
      ],
      "metadata": {
        "id": "21DWTMMQcl4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from Bio import SeqIO\n",
        "\n",
        "# Read cluster file and create a dictionary mapping sequences to clusters\n",
        "def parse_cluster_file(cluster_file):\n",
        "    clusters = {}\n",
        "    current_cluster = None\n",
        "    with open(cluster_file, 'r') as f:\n",
        "        for line in f:\n",
        "            if line.startswith('>Cluster'):\n",
        "                current_cluster = line.strip()\n",
        "                clusters[current_cluster] = []\n",
        "            else:\n",
        "                sequence_id = line.strip().split(\">\")[1].split(\"...\")[0]\n",
        "                clusters[current_cluster].append(sequence_id)\n",
        "    return clusters\n",
        "\n",
        "# Split clusters into training, evaluation, and testing sets\n",
        "def split_clusters(clusters, train_ratio=0.7, eval_ratio=0.2):\n",
        "    cluster_keys = list(clusters.keys())\n",
        "    random.shuffle(cluster_keys)\n",
        "    train_split_point = int(train_ratio * len(cluster_keys))\n",
        "    eval_split_point = int((train_ratio + eval_ratio) * len(cluster_keys))\n",
        "\n",
        "    train_clusters = {key: clusters[key] for key in cluster_keys[:train_split_point]}\n",
        "    eval_clusters = {key: clusters[key] for key in cluster_keys[train_split_point:eval_split_point]}\n",
        "    test_clusters = {key: clusters[key] for key in cluster_keys[eval_split_point:]}\n",
        "\n",
        "    return train_clusters, eval_clusters, test_clusters\n",
        "\n",
        "# Write sequences to fasta file based on clusters\n",
        "def write_fasta_file(original_fasta_file, clusters, output_file):\n",
        "    sequences = SeqIO.to_dict(SeqIO.parse(original_fasta_file, \"fasta\"))\n",
        "    selected_sequences = []\n",
        "\n",
        "    for cluster in clusters.values():\n",
        "        for seq_id in cluster:\n",
        "            if seq_id in sequences:\n",
        "                selected_sequences.append(sequences[seq_id])\n",
        "\n",
        "    SeqIO.write(selected_sequences, output_file, \"fasta\")\n",
        "\n",
        "# Main script\n",
        "cluster_file = 'clustered_ZN.fasta.clstr'\n",
        "original_fasta_file = 'ZN_samples.fasta'\n",
        "train_output_file = 'train_set.fasta'\n",
        "eval_output_file = 'eval_set.fasta'\n",
        "test_output_file = 'test_set.fasta'\n",
        "\n",
        "# Parse the cluster file\n",
        "clusters = parse_cluster_file(cluster_file)\n",
        "\n",
        "# Split clusters into training, evaluation, and testing sets\n",
        "train_clusters, eval_clusters, test_clusters = split_clusters(clusters)\n",
        "\n",
        "# Write training, evaluation, and testing fasta files\n",
        "write_fasta_file(original_fasta_file, train_clusters, train_output_file)\n",
        "write_fasta_file(original_fasta_file, eval_clusters, eval_output_file)\n",
        "write_fasta_file(original_fasta_file, test_clusters, test_output_file)\n",
        "\n",
        "print(f'Training set saved to {train_output_file}')\n",
        "print(f'Evaluation set saved to {eval_output_file}')\n",
        "print(f'Testing set saved to {test_output_file}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65ZKXyACctcF",
        "outputId": "d90cea8d-5e7c-488f-8844-7426ea3cd796"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set saved to train_set.fasta\n",
            "Evaluation set saved to eval_set.fasta\n",
            "Testing set saved to test_set.fasta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Splitting the labels (training and testing)"
      ],
      "metadata": {
        "id": "QIJARLcrxPQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio import SeqIO\n",
        "\n",
        "# Function to extract labels\n",
        "def extract_labels(fasta_file, labels_file, output_file):\n",
        "    # Read sequence IDs from the fasta file\n",
        "    sequence_ids = [record.id for record in SeqIO.parse(fasta_file, \"fasta\")]\n",
        "\n",
        "    # Open labels file and extract the labels for the corresponding sequence IDs\n",
        "    with open(labels_file, 'r') as labels_f, open(output_file, 'w') as out_f:\n",
        "        write_label = False\n",
        "        for line in labels_f:\n",
        "            if line.startswith('>'):\n",
        "                seq_id = line.strip().split('>')[1]\n",
        "                if seq_id in sequence_ids:\n",
        "                    write_label = True\n",
        "                    out_f.write(line)\n",
        "                else:\n",
        "                    write_label = False\n",
        "            elif write_label:\n",
        "                out_f.write(line)\n",
        "\n",
        "# File paths\n",
        "train_fasta = 'train_set.fasta'\n",
        "test_fasta = 'test_set.fasta'\n",
        "labels_fasta = 'ZN_labels.fasta'  # this line should be changed\n",
        "\n",
        "# Output files\n",
        "train_labels_output = 'train_labels.fasta'\n",
        "test_labels_output = 'test_labels.fasta'\n",
        "\n",
        "# Extract labels\n",
        "extract_labels(train_fasta, labels_fasta, train_labels_output)\n",
        "extract_labels(test_fasta, labels_fasta, test_labels_output)\n",
        "\n",
        "print(\"Labels extracted and saved to respective files.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6j535ONyxQPK",
        "outputId": "6da368d7-49a1-4ed8-8b1a-7258cf95f062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels extracted and saved to respective files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Splitting the labels (training, evaluating, and testing)"
      ],
      "metadata": {
        "id": "t3w0C6soc0W6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio import SeqIO\n",
        "\n",
        "# Function to extract labels\n",
        "def extract_labels(fasta_file, labels_file, output_file):\n",
        "    # Read sequence IDs from the fasta file\n",
        "    sequence_ids = [record.id for record in SeqIO.parse(fasta_file, \"fasta\")]\n",
        "\n",
        "    # Open labels file and extract the labels for the corresponding sequence IDs\n",
        "    with open(labels_file, 'r') as labels_f, open(output_file, 'w') as out_f:\n",
        "        write_label = False\n",
        "        for line in labels_f:\n",
        "            if line.startswith('>'):\n",
        "                seq_id = line.strip().split('>')[1]\n",
        "                if seq_id in sequence_ids:\n",
        "                    write_label = True\n",
        "                    out_f.write(line)\n",
        "                else:\n",
        "                    write_label = False\n",
        "            elif write_label:\n",
        "                out_f.write(line)\n",
        "\n",
        "# File paths\n",
        "train_fasta = 'train_set.fasta'\n",
        "eval_fasta = 'eval_set.fasta'\n",
        "test_fasta = 'test_set.fasta'\n",
        "labels_fasta = 'ZN_labels.fasta'  # Update this line if needed\n",
        "\n",
        "# Output files\n",
        "train_labels_output = 'train_labels.fasta'\n",
        "eval_labels_output = 'eval_labels.fasta'\n",
        "test_labels_output = 'test_labels.fasta'\n",
        "\n",
        "# Extract labels for each set\n",
        "extract_labels(train_fasta, labels_fasta, train_labels_output)\n",
        "extract_labels(eval_fasta, labels_fasta, eval_labels_output)\n",
        "extract_labels(test_fasta, labels_fasta, test_labels_output)\n",
        "\n",
        "print(\"Labels extracted and saved to respective files.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxNN_6jdc0BS",
        "outputId": "2cfe5630-5084-41c4-8897-3d9ad565ee39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels extracted and saved to respective files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sorting (training and testing)"
      ],
      "metadata": {
        "id": "YlLfCE_ZyrWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio import SeqIO\n",
        "\n",
        "def sort_fasta_sequences(input_file, output_file):\n",
        "    # Read the sequences from the input file\n",
        "    sequences = list(SeqIO.parse(input_file, \"fasta\"))\n",
        "\n",
        "    # Sort the sequences by the sequence id\n",
        "    sequences.sort(key=lambda x: x.id)\n",
        "\n",
        "    # Write the sorted sequences to the output file\n",
        "    SeqIO.write(sequences, output_file, \"fasta\")\n",
        "\n",
        "# Define the input and output files for the training set\n",
        "train_input_file = \"train_set.fasta\"\n",
        "train_output_file = \"sorted_train_set.fasta\"\n",
        "train_labels_input_file = \"train_labels.fasta\"\n",
        "train_labels_output_file = \"sorted_train_labels.fasta\"\n",
        "\n",
        "# Define the input and output files for the test set\n",
        "test_input_file = \"test_set.fasta\"\n",
        "test_output_file = \"sorted_test_set.fasta\"\n",
        "test_labels_input_file = \"test_labels.fasta\"\n",
        "test_labels_output_file = \"sorted_test_labels.fasta\"\n",
        "\n",
        "# Sort the sequences in the training set\n",
        "sort_fasta_sequences(train_input_file, train_output_file)\n",
        "sort_fasta_sequences(train_labels_input_file, train_labels_output_file)\n",
        "\n",
        "# Sort the sequences in the test set\n",
        "sort_fasta_sequences(test_input_file, test_output_file)\n",
        "sort_fasta_sequences(test_labels_input_file, test_labels_output_file)\n",
        "\n",
        "print(\"Sorting completed and files saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PLaDoJvysYo",
        "outputId": "747e0704-f38f-4683-fe7e-a7daec9cb949"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorting completed and files saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sorting (training, evaluating, and testing)"
      ],
      "metadata": {
        "id": "k2QvheEGdhWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio import SeqIO\n",
        "\n",
        "def sort_fasta_sequences(input_file, output_file):\n",
        "    # Read the sequences from the input file\n",
        "    sequences = list(SeqIO.parse(input_file, \"fasta\"))\n",
        "\n",
        "    # Sort the sequences by the sequence id\n",
        "    sequences.sort(key=lambda x: x.id)\n",
        "\n",
        "    # Write the sorted sequences to the output file\n",
        "    SeqIO.write(sequences, output_file, \"fasta\")\n",
        "\n",
        "# Define the input and output files for the training set\n",
        "train_input_file = \"train_set.fasta\"\n",
        "train_output_file = \"sorted_train_set.fasta\"\n",
        "train_labels_input_file = \"train_labels.fasta\"\n",
        "train_labels_output_file = \"sorted_train_labels.fasta\"\n",
        "\n",
        "# Define the input and output files for the evaluation set\n",
        "eval_input_file = \"eval_set.fasta\"\n",
        "eval_output_file = \"sorted_eval_set.fasta\"\n",
        "eval_labels_input_file = \"eval_labels.fasta\"\n",
        "eval_labels_output_file = \"sorted_eval_labels.fasta\"\n",
        "\n",
        "# Define the input and output files for the test set\n",
        "test_input_file = \"test_set.fasta\"\n",
        "test_output_file = \"sorted_test_set.fasta\"\n",
        "test_labels_input_file = \"test_labels.fasta\"\n",
        "test_labels_output_file = \"sorted_test_labels.fasta\"\n",
        "\n",
        "# Sort the sequences in the training set\n",
        "sort_fasta_sequences(train_input_file, train_output_file)\n",
        "sort_fasta_sequences(train_labels_input_file, train_labels_output_file)\n",
        "\n",
        "# Sort the sequences in the evaluation set\n",
        "sort_fasta_sequences(eval_input_file, eval_output_file)\n",
        "sort_fasta_sequences(eval_labels_input_file, eval_labels_output_file)\n",
        "\n",
        "# Sort the sequences in the test set\n",
        "sort_fasta_sequences(test_input_file, test_output_file)\n",
        "sort_fasta_sequences(test_labels_input_file, test_labels_output_file)\n",
        "\n",
        "print(\"Sorting completed and files saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzaHiMp-dkvc",
        "outputId": "5da0beaf-5460-430e-fc7c-3fe26803a2bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorting completed and files saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Check that sequences from the same cluster are not split across the training, evaluation, and testing sets"
      ],
      "metadata": {
        "id": "8haNl-3Ikd-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio import SeqIO\n",
        "\n",
        "def parse_cluster_file(cluster_file):\n",
        "    clusters = {}\n",
        "    current_cluster = None\n",
        "    with open(cluster_file, 'r') as f:\n",
        "        for line in f:\n",
        "            if line.startswith('>Cluster'):\n",
        "                current_cluster = line.strip()\n",
        "                clusters[current_cluster] = []\n",
        "            else:\n",
        "                sequence_id = line.strip().split(\">\")[1].split(\"...\")[0]\n",
        "                clusters[current_cluster].append(sequence_id)\n",
        "    return clusters\n",
        "\n",
        "def check_cluster_integrity(train_file, eval_file, test_file, cluster_file):\n",
        "    # Load sequence IDs from each set\n",
        "    train_ids = {record.id for record in SeqIO.parse(train_file, \"fasta\")}\n",
        "    eval_ids = {record.id for record in SeqIO.parse(eval_file, \"fasta\")}\n",
        "    test_ids = {record.id for record in SeqIO.parse(test_file, \"fasta\")}\n",
        "\n",
        "    # Print total number of sequences in each set\n",
        "    print(f\"Total sequences in Training set: {len(train_ids)}\")\n",
        "    print(f\"Total sequences in Evaluation set: {len(eval_ids)}\")\n",
        "    print(f\"Total sequences in Testing set: {len(test_ids)}\")\n",
        "\n",
        "    # Parse cluster information\n",
        "    clusters = parse_cluster_file(cluster_file)\n",
        "\n",
        "    # Check that no sequences from the same cluster are in different sets\n",
        "    for cluster, seq_ids in clusters.items():\n",
        "        sets = set()\n",
        "        for seq_id in seq_ids:\n",
        "            if seq_id in train_ids:\n",
        "                sets.add('Training')\n",
        "            if seq_id in eval_ids:\n",
        "                sets.add('Evaluation')\n",
        "            if seq_id in test_ids:\n",
        "                sets.add('Testing')\n",
        "\n",
        "        if len(sets) > 1:\n",
        "            print(f\"Cluster {cluster} spans multiple sets: {sets} (Number of sequences: {len(seq_ids)})\")\n",
        "        else:\n",
        "            print(f\"Cluster {cluster} is only in one set: {sets} (Number of sequences: {len(seq_ids)})\")\n",
        "\n",
        "# File paths\n",
        "train_file = 'sorted_train_set.fasta'\n",
        "eval_file = 'sorted_eval_set.fasta'\n",
        "test_file = 'sorted_test_set.fasta'\n",
        "cluster_file = 'clustered_ZN.fasta.clstr'\n",
        "\n",
        "# Perform the check\n",
        "check_cluster_integrity(train_file, eval_file, test_file, cluster_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8B1R_KOjmqxw",
        "outputId": "79c07085-3f92-419e-e258-0267fbd7ca2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sequences in Training set: 377\n",
            "Total sequences in Evaluation set: 63\n",
            "Total sequences in Testing set: 41\n",
            "Cluster >Cluster 0 is only in one set: {'Training'} (Number of sequences: 2)\n",
            "Cluster >Cluster 1 is only in one set: {'Training'} (Number of sequences: 2)\n",
            "Cluster >Cluster 2 is only in one set: {'Testing'} (Number of sequences: 10)\n",
            "Cluster >Cluster 3 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 4 is only in one set: {'Training'} (Number of sequences: 31)\n",
            "Cluster >Cluster 5 is only in one set: {'Training'} (Number of sequences: 2)\n",
            "Cluster >Cluster 6 is only in one set: {'Training'} (Number of sequences: 2)\n",
            "Cluster >Cluster 7 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 8 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 9 is only in one set: {'Training'} (Number of sequences: 2)\n",
            "Cluster >Cluster 10 is only in one set: {'Testing'} (Number of sequences: 2)\n",
            "Cluster >Cluster 11 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 12 is only in one set: {'Testing'} (Number of sequences: 1)\n",
            "Cluster >Cluster 13 is only in one set: {'Training'} (Number of sequences: 2)\n",
            "Cluster >Cluster 14 is only in one set: {'Testing'} (Number of sequences: 1)\n",
            "Cluster >Cluster 15 is only in one set: {'Training'} (Number of sequences: 20)\n",
            "Cluster >Cluster 16 is only in one set: {'Training'} (Number of sequences: 30)\n",
            "Cluster >Cluster 17 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 18 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 19 is only in one set: {'Training'} (Number of sequences: 11)\n",
            "Cluster >Cluster 20 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 21 is only in one set: {'Training'} (Number of sequences: 9)\n",
            "Cluster >Cluster 22 is only in one set: {'Evaluation'} (Number of sequences: 4)\n",
            "Cluster >Cluster 23 is only in one set: {'Training'} (Number of sequences: 2)\n",
            "Cluster >Cluster 24 is only in one set: {'Training'} (Number of sequences: 40)\n",
            "Cluster >Cluster 25 is only in one set: {'Testing'} (Number of sequences: 3)\n",
            "Cluster >Cluster 26 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 27 is only in one set: {'Testing'} (Number of sequences: 4)\n",
            "Cluster >Cluster 28 is only in one set: {'Testing'} (Number of sequences: 5)\n",
            "Cluster >Cluster 29 is only in one set: {'Evaluation'} (Number of sequences: 4)\n",
            "Cluster >Cluster 30 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 31 is only in one set: {'Testing'} (Number of sequences: 9)\n",
            "Cluster >Cluster 32 is only in one set: {'Evaluation'} (Number of sequences: 2)\n",
            "Cluster >Cluster 33 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 34 is only in one set: {'Training'} (Number of sequences: 2)\n",
            "Cluster >Cluster 35 is only in one set: {'Evaluation'} (Number of sequences: 1)\n",
            "Cluster >Cluster 36 is only in one set: {'Training'} (Number of sequences: 2)\n",
            "Cluster >Cluster 37 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 38 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 39 is only in one set: {'Training'} (Number of sequences: 4)\n",
            "Cluster >Cluster 40 is only in one set: {'Evaluation'} (Number of sequences: 2)\n",
            "Cluster >Cluster 41 is only in one set: {'Training'} (Number of sequences: 2)\n",
            "Cluster >Cluster 42 is only in one set: {'Evaluation'} (Number of sequences: 2)\n",
            "Cluster >Cluster 43 is only in one set: {'Evaluation'} (Number of sequences: 1)\n",
            "Cluster >Cluster 44 is only in one set: {'Testing'} (Number of sequences: 1)\n",
            "Cluster >Cluster 45 is only in one set: {'Evaluation'} (Number of sequences: 1)\n",
            "Cluster >Cluster 46 is only in one set: {'Evaluation'} (Number of sequences: 2)\n",
            "Cluster >Cluster 47 is only in one set: {'Training'} (Number of sequences: 57)\n",
            "Cluster >Cluster 48 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 49 is only in one set: {'Testing'} (Number of sequences: 1)\n",
            "Cluster >Cluster 50 is only in one set: {'Evaluation'} (Number of sequences: 2)\n",
            "Cluster >Cluster 51 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 52 is only in one set: {'Evaluation'} (Number of sequences: 2)\n",
            "Cluster >Cluster 53 is only in one set: {'Testing'} (Number of sequences: 2)\n",
            "Cluster >Cluster 54 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 55 is only in one set: {'Evaluation'} (Number of sequences: 4)\n",
            "Cluster >Cluster 56 is only in one set: {'Evaluation'} (Number of sequences: 3)\n",
            "Cluster >Cluster 57 is only in one set: {'Training'} (Number of sequences: 5)\n",
            "Cluster >Cluster 58 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 59 is only in one set: {'Evaluation'} (Number of sequences: 4)\n",
            "Cluster >Cluster 60 is only in one set: {'Training'} (Number of sequences: 12)\n",
            "Cluster >Cluster 61 is only in one set: {'Training'} (Number of sequences: 4)\n",
            "Cluster >Cluster 62 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 63 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 64 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 65 is only in one set: {'Training'} (Number of sequences: 6)\n",
            "Cluster >Cluster 66 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 67 is only in one set: {'Training'} (Number of sequences: 4)\n",
            "Cluster >Cluster 68 is only in one set: {'Training'} (Number of sequences: 2)\n",
            "Cluster >Cluster 69 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 70 is only in one set: {'Evaluation'} (Number of sequences: 8)\n",
            "Cluster >Cluster 71 is only in one set: {'Evaluation'} (Number of sequences: 1)\n",
            "Cluster >Cluster 72 is only in one set: {'Training'} (Number of sequences: 6)\n",
            "Cluster >Cluster 73 is only in one set: {'Training'} (Number of sequences: 4)\n",
            "Cluster >Cluster 74 is only in one set: {'Training'} (Number of sequences: 2)\n",
            "Cluster >Cluster 75 is only in one set: {'Training'} (Number of sequences: 6)\n",
            "Cluster >Cluster 76 is only in one set: {'Evaluation'} (Number of sequences: 12)\n",
            "Cluster >Cluster 77 is only in one set: {'Training'} (Number of sequences: 4)\n",
            "Cluster >Cluster 78 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 79 is only in one set: {'Training'} (Number of sequences: 4)\n",
            "Cluster >Cluster 80 is only in one set: {'Training'} (Number of sequences: 13)\n",
            "Cluster >Cluster 81 is only in one set: {'Training'} (Number of sequences: 6)\n",
            "Cluster >Cluster 82 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 83 is only in one set: {'Training'} (Number of sequences: 2)\n",
            "Cluster >Cluster 84 is only in one set: {'Training'} (Number of sequences: 4)\n",
            "Cluster >Cluster 85 is only in one set: {'Evaluation'} (Number of sequences: 1)\n",
            "Cluster >Cluster 86 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 87 is only in one set: {'Training'} (Number of sequences: 4)\n",
            "Cluster >Cluster 88 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 89 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 90 is only in one set: {'Training'} (Number of sequences: 2)\n",
            "Cluster >Cluster 91 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 92 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 93 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 94 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 95 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 96 is only in one set: {'Training'} (Number of sequences: 16)\n",
            "Cluster >Cluster 97 is only in one set: {'Testing'} (Number of sequences: 2)\n",
            "Cluster >Cluster 98 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 99 is only in one set: {'Training'} (Number of sequences: 3)\n",
            "Cluster >Cluster 100 is only in one set: {'Training'} (Number of sequences: 2)\n",
            "Cluster >Cluster 101 is only in one set: {'Evaluation'} (Number of sequences: 1)\n",
            "Cluster >Cluster 102 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 103 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 104 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 105 is only in one set: {'Evaluation'} (Number of sequences: 1)\n",
            "Cluster >Cluster 106 is only in one set: {'Evaluation'} (Number of sequences: 2)\n",
            "Cluster >Cluster 107 is only in one set: {'Evaluation'} (Number of sequences: 1)\n",
            "Cluster >Cluster 108 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 109 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 110 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 111 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 112 is only in one set: {'Evaluation'} (Number of sequences: 1)\n",
            "Cluster >Cluster 113 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 114 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 115 is only in one set: {'Evaluation'} (Number of sequences: 1)\n",
            "Cluster >Cluster 116 is only in one set: {'Training'} (Number of sequences: 1)\n",
            "Cluster >Cluster 117 is only in one set: {'Training'} (Number of sequences: 2)\n"
          ]
        }
      ]
    }
  ]
}